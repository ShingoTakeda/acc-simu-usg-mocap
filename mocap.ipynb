{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats as s\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.cross_validation as crv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_name():\n",
    "    p0 = ['x','y','z']\n",
    "    marker =[]\n",
    "    p2 =[]\n",
    "    for a in range(1,44):       #Mocapマーカー数:43個\n",
    "        p1='m'+ str(a)\n",
    "        for b in p0:\n",
    "            p2 = p1 + b\n",
    "            marker.append(p2)\n",
    "    return marker\n",
    "\n",
    "def read_mocap(file):\n",
    "    data_mocap = pd.read_csv(file,sep=' ',header=None)\n",
    "    #座標値列の列名変更\n",
    "    data_mocap=data_mocap.rename(columns={data_mocap.columns[a]:col_name()[a] for a in range(129)} )\n",
    "    #座標値列以外の列名変更\n",
    "    data_mocap=data_mocap.rename(columns={129:'FrameNumber',130:'TimeStamp'})\n",
    "    return data_mocap\n",
    "\n",
    "#fix NaN\n",
    "def fix_NaN(data):\n",
    "    for  c  in  data.columns:\n",
    "        col = data[c]  #'X'列から1列ずつ見る\n",
    "        for r in range(len(data)):  #1行ずつ見る\n",
    "            if col[r] == 0.0:       #0値が見つかれば\n",
    "                data.iloc[r][c] = 'NaN' #'NaN'を代入\n",
    "    mc_clean = data.interpolate()\n",
    "    mc_clean = mc_clean.fillna(0)\n",
    "    return mc_clean\n",
    "\n",
    "def obtain_statistical_feature(window):\n",
    "    #features = np.array(np.array(np.var(window, axis=0)))\n",
    "    #features=np.array(np.array(np.mean(window-np.mean(window), axis=0)))\n",
    "    features=np.array( np.array(np.mean(window-np.median(window), axis=0))) \n",
    "    features=np.append(features, np.array(np.std(window, axis=0))) \n",
    "    features=np.append(features, np.array(np.var(window, axis=0)))\n",
    "    features=np.append(features, np.array(s.skew(window, axis=0)))\n",
    "    features=np.append(features, np.array(s.kurtosis(window, axis=0)))\n",
    "    features=np.append(features, np.array(get_tw_variance(window)))\n",
    "    return features.reshape(1,len(features))\n",
    "\n",
    "\n",
    "def get_tw_variance(window):\n",
    "    total_cols = window.shape[1]\n",
    "    tw_var = []\n",
    "    for i in range (total_cols):\n",
    "        column = window.iloc[:,i]\n",
    "        tw_var.append(get_tw_col_var(column))\n",
    "    return tw_var\n",
    "\n",
    "\n",
    "def get_tw_col_var(column):\n",
    "    mean = np.mean(column)\n",
    "    total = len(column)\n",
    "    \n",
    "    v_sum = 0\n",
    "    for i in range(total):\n",
    "        w = np.exp(-0.5*(total-i))\n",
    "        #print(\"el peso\", w, \"indice\", i, \"total\", total)\n",
    "        v = w*np.square(column.iloc[i]-mean)\n",
    "        v_sum += v\n",
    "    return v_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_functuion(sampling_rate,*markers):\n",
    "    x = np.empty([0,3*6*len(markers)])\n",
    "    y = np.empty([0,])\n",
    "    #Read all mocap data\n",
    "    subjects =  [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "    actions = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"]\n",
    "    for subject in subjects:\n",
    "        for action in actions:\n",
    "            for record in range(1,6):\n",
    "                try:\n",
    "                    data = read_mocap('/Users/takeshin/ws/BerkeleyMHAD/Mocap/OpticalData/moc_s'+str(subject)+'_a'+str(action)+'_r0'+str(record)+'.txt')\n",
    "                    print('moc_s'+str(subject)+'_a'+str(action)+'_r0'+str(record)+'.txt')\n",
    "                    columns = [['m'+str(i)+'x','m'+str(i)+'y','m'+str(i)+'z'] for i in markers]\n",
    "                    cols = np.array(columns)\n",
    "                    cols = list(np.ravel(cols))\n",
    "                    cols.append(\"TimeStamp\")\n",
    "                    data = data[cols]\n",
    "                    \n",
    "                    data = fix_NaN(data)\n",
    "                    i = 0\n",
    "                    mc_ds = pd.DataFrame()\n",
    "                    #処理\n",
    "                    while  i < (len(data)//(480//sampling_rate))*(480//sampling_rate):\n",
    "                        mc_ds = mc_ds.append(data.iloc[i : i+(480//sampling_rate),:].mean(),ignore_index=True)\n",
    "                        i+=(480//sampling_rate)\n",
    "                    mc_ds = mc_ds.append(data.iloc[i : i+(480//sampling_rate)-1,:].mean(),ignore_index=True)\n",
    "                   \n",
    "                    sf = obtain_statistical_feature(mc_ds.loc[:, mc_ds.columns != 'TimeStamp'])\n",
    "\n",
    "                    x =np.append(x,sf, axis=0)\n",
    "                    y = np.append(y,[action], axis=0)\n",
    "                \n",
    "                \n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "                    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y=main_functuion(30,16)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_ar(X,y):\n",
    "    x_train, x_test, y_train, y_test = crv.train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    print (accuracy_score(y_test, y_predict) ) \n",
    "    actions = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"]\n",
    "    print(classification_report(y_test, y_predict, target_names=actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_ar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_ar2(X,y):                              \n",
    "    #Try classifier\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('clf', SVC(kernel='linear')))\n",
    "    model = Pipeline(estimators)\n",
    "    \n",
    "    seed = 11\n",
    "    kf = KFold(n_splits=3, random_state=seed, shuffle=True)\n",
    "    accuracy = [] \n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        acc_train = model.score(X_train, y_train)\n",
    "        acc_test = model.score(X_test, y_test)\n",
    "        accuracy.append(acc_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        conf = confusion_matrix(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred,average='macro') \n",
    "        recall = recall_score(y_test, y_pred,average='macro')\n",
    "        print(\"*Accuracy* train:\",acc_train, \"test:\",acc_test)\n",
    "        #print(conf)\n",
    "        #print (\"precision:\",precision,\"recall:\",recall)\n",
    "        actions = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\"]\n",
    "        #actions = [\"Jumping in place\",\"Jumping jacks\",\"Bending-hands up all the way down\",\"Punching(boxing)\",\"Waving-two hands\",\"Waving - one hand (right)\",\"Clapping hands\",\"Throwing a ball\",\"09\",\"10\",\"11\"]\n",
    "        print(classification_report(y_test, y_pred, target_names=actions))\n",
    "        print(\"-----------\")\n",
    "    print(\"*test_ave*\",sum(accuracy)/len(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
